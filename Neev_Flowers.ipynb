{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "813d66f5-19e4-45e1-8286-9e527ed8a340",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\letap\\AppData\\Local\\Temp\\ipykernel_21032\\2326916955.py:4: DeprecationWarning: 'imghdr' is deprecated and slated for removal in Python 3.13\n",
      "  import imghdr\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import imghdr\n",
    "import tensorflow as tf\n",
    "\n",
    "def is_image_file(path):\n",
    "    if not os.path.isfile(path):\n",
    "        return False\n",
    "    image_type = imghdr.what(path)\n",
    "    return image_type is not None\n",
    "\n",
    "folder_path = \"C:/Users/letap/anaconda_projects/Class_Carnations\"\n",
    "\n",
    "Carnations_arr = []\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    if is_image_file(file_path):\n",
    "        image = tf.io.read_file(file_path)\n",
    "        image_tensor = tf.image.decode_jpeg(image, channels=3)\n",
    "        image = tf.image.resize(image_tensor, [256, 256])\n",
    "        image_array = tf.cast(image, tf.uint8)\n",
    "        Carnations_arr.append(image_array)\n",
    "\n",
    "folder_path2 = \"C:/Users/letap/anaconda_projects/Class_Roses\"\n",
    "\n",
    "Roses_arr = []\n",
    "\n",
    "for filename in os.listdir(folder_path2):\n",
    "    file_path = os.path.join(folder_path2, filename)\n",
    "    if is_image_file(file_path):\n",
    "        image = tf.io.read_file(file_path)\n",
    "        image_tensor = tf.image.decode_jpeg(image, channels=3)\n",
    "        image = tf.image.resize(image_tensor, [256, 256])\n",
    "        image_array = tf.cast(image, tf.uint8)\n",
    "        Roses_arr.append(image_array)\n",
    "\n",
    "folder_path3 = \"C:/Users/letap/anaconda_projects/Roses_Validation\"\n",
    "\n",
    "Roses_val = []\n",
    "\n",
    "for filename in os.listdir(folder_path3):\n",
    "    file_path = os.path.join(folder_path3, filename)\n",
    "    if is_image_file(file_path):\n",
    "        image = tf.io.read_file(file_path)\n",
    "        image_tensor = tf.image.decode_jpeg(image, channels=3)\n",
    "        image = tf.image.resize(image_tensor, [256, 256])\n",
    "        image_array = tf.cast(image, tf.uint8)\n",
    "        Roses_val.append(image_array)\n",
    "\n",
    "folder_path4 = \"C:/Users/letap/anaconda_projects/Carnations_Validation\"\n",
    "\n",
    "Carnations_val = []\n",
    "\n",
    "for filename in os.listdir(folder_path4):\n",
    "    file_path = os.path.join(folder_path4, filename)\n",
    "    if is_image_file(file_path):\n",
    "        image = tf.io.read_file(file_path)\n",
    "        image_tensor = tf.image.decode_jpeg(image, channels=3)\n",
    "        image = tf.image.resize(image_tensor, [256, 256])\n",
    "        image_array = tf.cast(image, tf.uint8)\n",
    "        Carnations_val.append(image_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f923668-78a4-4fe5-878b-f3da1cfc7f8f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Roses_arr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m labels1 \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      2\u001b[0m validation_labels1 \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m Roses_arr:\n\u001b[0;32m      5\u001b[0m     labels1\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m Carnations_arr:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Roses_arr' is not defined"
     ]
    }
   ],
   "source": [
    "labels1 = []\n",
    "validation_labels1 = []\n",
    "\n",
    "for i in Roses_arr:\n",
    "    labels1.append(0)\n",
    "for i in Carnations_arr:\n",
    "    labels1.append(1)\n",
    "for i in Roses_val:\n",
    "    validation_labels1.append(0)\n",
    "for i in Carnations_val:\n",
    "    validation_labels1.append(1)\n",
    "\n",
    "training_images1 = Roses_arr + Carnations_arr\n",
    "testing_images1 = Roses_val + Carnations_val\n",
    "\n",
    "training_images = np.array(training_images1, dtype=np.float32)\n",
    "testing_images = np.array(testing_images1, dtype=np.float32)\n",
    "labels = np.array(labels1, dtype=np.int32)\n",
    "validation_labels = np.array(validation_labels1, dtype=np.int32)\n",
    "\n",
    "training_images = training_images/255.0\n",
    "testing_images = testing_images/255.0\n",
    "\n",
    "print(len(training_images))\n",
    "print(len(testing_images))\n",
    "\n",
    "print(len(labels))\n",
    "print(len(validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81110371-2262-48a6-8a85-23ad5e7f5689",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 20\u001b[0m\n\u001b[0;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[0;32m      8\u001b[0m                         tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mConv2D(\u001b[38;5;241m64\u001b[39m, (\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m3\u001b[39m), activation \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      9\u001b[0m                                                input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m256\u001b[39m,\u001b[38;5;241m256\u001b[39m,\u001b[38;5;241m3\u001b[39m)),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m                         keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m2\u001b[39m, activation\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39msoftmax)\n\u001b[0;32m     14\u001b[0m                          ])\n\u001b[0;32m     16\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     17\u001b[0m               loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     18\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 20\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(training_images, labels, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'training_images' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "                        tf.keras.layers.Conv2D(64, (3,3), activation = 'relu',\n",
    "                                               input_shape=(256,256,3)),\n",
    "                        tf.keras.layers.AveragePooling2D(2,2),\n",
    "                        keras.layers.Flatten(),\n",
    "                        keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "                        keras.layers.Dense(2, activation=tf.nn.softmax)\n",
    "                         ])\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(training_images, labels, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9ca0f4a-cc70-446d-9791-7e6c66b2b4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - accuracy: 0.6005 - loss: 0.7127\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6982843279838562, 0.6375839114189148]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(testing_images, validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e393c95-4356-4cf3-93e0-fa0deabb2130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 256, 256, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_path5 = \"C:/Users/letap/anaconda_projects/Test\"\n",
    "\n",
    "test_arr = []\n",
    "\n",
    "for filename in os.listdir(folder_path5):\n",
    "    file_path = os.path.join(folder_path5, filename)\n",
    "    if is_image_file(file_path):\n",
    "        image = tf.io.read_file(file_path)\n",
    "        image_tensor = tf.image.decode_jpeg(image, channels=3)\n",
    "        image = tf.image.resize(image_tensor, [256, 256])\n",
    "        image_array = tf.cast(image, tf.uint8)\n",
    "        test_arr.append(image_array)\n",
    "\n",
    "test = np.array(test_arr, dtype=np.float32)\n",
    "test = test / 255.0\n",
    "\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe3f5661-ff1e-4c08-90bd-edd5e6b20f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.12357719, 0.87642276],\n",
       "       [0.38700166, 0.61299837],\n",
       "       [0.9392859 , 0.06071415],\n",
       "       [0.72295904, 0.277041  ]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58093bc2-7da3-4e3a-9924-583cadfd5603",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
